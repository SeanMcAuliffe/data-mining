{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENG 474 A02: Assignment 1\n",
    "Sean McAuliffe, V00913346  \n",
    "February 4, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step installs the project requirements and imports modules used for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy\n",
    "# !pip3 install pandas\n",
    "# !pip3 install sklearn\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install graphviz\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preprocessing\n",
    "This block is to load in the cleaned_adult.csv file, to shuffle the examlples, and to partition the data into training + test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the income dataset...\n",
      "\n",
      "Dataset Features:\n",
      "  Num. dimensions: 2\n",
      "  Data shape: (45222, 104)\n",
      "  Size: 4703088\n",
      "\n",
      "Dataset Labels:\n",
      "  Num. dimensions: 1\n",
      "  Data shape: (45222,)\n",
      "  Size: 45222\n",
      "\n",
      "Training Features:\n",
      "  Num. dimensions: 2\n",
      "  Data shape: (36177, 104)\n",
      "  Size: 3762408\n",
      "\n",
      "Training Labels:\n",
      "  Num. dimensions: 1\n",
      "  Data shape: (36177,)\n",
      "  Size: 36177\n",
      "\n",
      "Testing Features:\n",
      "  Num. dimensions: 2\n",
      "  Data shape: (9045, 104)\n",
      "  Size: 940680\n",
      "\n",
      "Testing Labels:\n",
      "  Num. dimensions: 1\n",
      "  Data shape: (9045,)\n",
      "  Size: 9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset from .csv\n",
    "print(\"Importing the income dataset...\\n\")\n",
    "income_dataset = np.genfromtxt('./cleaned_adult.csv', delimiter=',', skip_header=1, dtype=int)\n",
    "\n",
    "# Shuffle the rows of the dataset so that examples appear in random order\n",
    "np.random.shuffle(income_dataset)\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "dataset_features = income_dataset[:, :-1]\n",
    "print(\"Dataset Features:\")\n",
    "print(f\"  Num. dimensions: {dataset_features.ndim}\")\n",
    "print(f\"  Data shape: {dataset_features.shape}\")\n",
    "print(f\"  Size: {dataset_features.size}\\n\")\n",
    "\n",
    "dataset_labels = income_dataset[:, -1]\n",
    "print(\"Dataset Labels:\")\n",
    "print(f\"  Num. dimensions: {dataset_labels.ndim}\")\n",
    "print(f\"  Data shape: {dataset_labels.shape}\")\n",
    "print(f\"  Size: {dataset_labels.size}\\n\")\n",
    "\n",
    "\n",
    "def split_dataset(features, labels, training_percent):\n",
    "    \"\"\" Split the dataset into training and testing sets \"\"\"\n",
    "    training_features = features[:int(training_percent * features.shape[0])]\n",
    "    training_labels = labels[:int(training_percent * labels.shape[0])]\n",
    "    testing_features = features[int(training_percent * features.shape[0]):]\n",
    "    testing_labels = labels[int(training_percent * labels.shape[0]):]\n",
    "    return training_features, training_labels, testing_features, testing_labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# With 80% of the data in the training set and 20% in the testing set\n",
    "training_features, training_labels, testing_features, testing_labels = split_dataset(dataset_features, dataset_labels, 0.8)\n",
    "\n",
    "\n",
    "print(\"Training Features:\")\n",
    "print(f\"  Num. dimensions: {training_features.ndim}\")\n",
    "print(f\"  Data shape: {training_features.shape}\")\n",
    "print(f\"  Size: {training_features.size}\\n\")\n",
    "\n",
    "print(\"Training Labels:\")\n",
    "print(f\"  Num. dimensions: {training_labels.ndim}\")\n",
    "print(f\"  Data shape: {training_labels.shape}\")\n",
    "print(f\"  Size: {training_labels.size}\\n\")\n",
    "\n",
    "print(\"Testing Features:\")\n",
    "print(f\"  Num. dimensions: {testing_features.ndim}\")\n",
    "print(f\"  Data shape: {testing_features.shape}\")\n",
    "print(f\"  Size: {testing_features.size}\\n\")\n",
    "\n",
    "print(\"Testing Labels:\")\n",
    "print(f\"  Num. dimensions: {testing_labels.ndim}\")\n",
    "print(f\"  Data shape: {testing_labels.shape}\")\n",
    "print(f\"  Size: {testing_labels.size}\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Decision Trees (With Pruning)\n",
    "1. Decision Tree: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "2. iris dataset: https://en.wikipedia.org/wiki/Iris_flower_data_set  \n",
    "3. hyperparameter Max_depth = The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "4. Post process pruning: https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the testing data: 80.88%\n"
     ]
    }
   ],
   "source": [
    "# This visualization function is taken from the Lab 1 code provided by the TA\n",
    "# Takes in a DecisionTreeClassifier model. X represents the data, y represents\n",
    "# the labels\n",
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    ax = ax or plt.gca()\n",
    "\n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # fit the estimator\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)\n",
    "\n",
    "# Fit a decision tree to the training data\n",
    "dtc = DecisionTreeClassifier(random_state=None, max_depth=None, splitter=\"best\", criterion=\"entropy\").fit(training_features, training_labels)\n",
    "model = dtc.fit(training_features, training_labels)\n",
    "\n",
    "# measure the accuracy of the model on the testing data\n",
    "print(\"Accuracy of the model on the testing data: {:.2f}%\".format(model.score(testing_features, testing_labels) * 100))\n",
    "\n",
    "# Post process pruning documentation\n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Random forests (Without Pruning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
